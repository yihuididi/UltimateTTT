{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480000\n",
      "160000\n"
     ]
    }
   ],
   "source": [
    "from utils import load_data\n",
    "trainset = load_data(\"trainset.pkl\")\n",
    "testset = load_data(\"testset.pkl\")\n",
    "print(len(trainset))\n",
    "print(len(testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils import State\n",
    "\n",
    "class FeatureExtractor:\n",
    "    FEATURES = 13\n",
    "\n",
    "    def extract_features(self, state: State):\n",
    "        if state.fill_num == 2:\n",
    "            state = self._inverse_state(state)\n",
    "\n",
    "        status = state.local_board_status\n",
    "        features = []\n",
    "        for x in range(3):\n",
    "            for y in range(3):\n",
    "                board = state.board[x, y]\n",
    "                get_value = [0, 1, -1]\n",
    "                features.append([\n",
    "                    self._check_actionable(state.prev_local_action, status, x, y),\n",
    "                    1 if status[x, y] == 1 else 0,\n",
    "                    1 if status[x, y] == 2 else 0,\n",
    "                    1 if status[x, y] == 3 else 0,\n",
    "                    get_value[board[0, 0]],\n",
    "                    get_value[board[0, 1]],\n",
    "                    get_value[board[0, 2]],\n",
    "                    get_value[board[1, 0]],\n",
    "                    get_value[board[1, 1]],\n",
    "                    get_value[board[1, 2]],\n",
    "                    get_value[board[2, 0]],\n",
    "                    get_value[board[2, 1]],\n",
    "                    get_value[board[2, 2]],\n",
    "                ])\n",
    "        return features\n",
    "\n",
    "    def _inverse_state(self, state):\n",
    "        inversed_fill_num = 2 if state.fill_num == 1 else 1\n",
    "        board = state.board\n",
    "        inversed_board = np.where(board == 1, 2, np.where(board == 2, 1, board))\n",
    "\n",
    "        return State(board=inversed_board, fill_num=inversed_fill_num, prev_local_action=state.prev_local_action)\n",
    "\n",
    "    def _check_actionable(self, prev_action, status, x, y):\n",
    "        if status[x, y] != 0:\n",
    "            return 0\n",
    "        if prev_action is None:\n",
    "            return 1\n",
    "        if status[prev_action[0], prev_action[1]] != 0:\n",
    "            return 1\n",
    "        return 1 if x == prev_action[0] and y == prev_action[1] else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10000 data in trainset\n",
      "Processed 20000 data in trainset\n",
      "Processed 30000 data in trainset\n",
      "Processed 40000 data in trainset\n",
      "Processed 50000 data in trainset\n",
      "Processed 60000 data in trainset\n",
      "Processed 70000 data in trainset\n",
      "Processed 80000 data in trainset\n",
      "Processed 90000 data in trainset\n",
      "Processed 100000 data in trainset\n",
      "Processed 110000 data in trainset\n",
      "Processed 120000 data in trainset\n",
      "Processed 130000 data in trainset\n",
      "Processed 140000 data in trainset\n",
      "Processed 150000 data in trainset\n",
      "Processed 160000 data in trainset\n",
      "Processed 170000 data in trainset\n",
      "Processed 180000 data in trainset\n",
      "Processed 190000 data in trainset\n",
      "Processed 200000 data in trainset\n",
      "Processed 210000 data in trainset\n",
      "Processed 220000 data in trainset\n",
      "Processed 230000 data in trainset\n",
      "Processed 240000 data in trainset\n",
      "Processed 250000 data in trainset\n",
      "Processed 260000 data in trainset\n",
      "Processed 270000 data in trainset\n",
      "Processed 280000 data in trainset\n",
      "Processed 290000 data in trainset\n",
      "Processed 300000 data in trainset\n",
      "Processed 310000 data in trainset\n",
      "Processed 320000 data in trainset\n",
      "Processed 330000 data in trainset\n",
      "Processed 340000 data in trainset\n",
      "Processed 350000 data in trainset\n",
      "Processed 360000 data in trainset\n",
      "Processed 370000 data in trainset\n",
      "Processed 380000 data in trainset\n",
      "Processed 390000 data in trainset\n",
      "Processed 400000 data in trainset\n",
      "Processed 410000 data in trainset\n",
      "Processed 420000 data in trainset\n",
      "Processed 430000 data in trainset\n",
      "Processed 440000 data in trainset\n",
      "Processed 450000 data in trainset\n",
      "Processed 460000 data in trainset\n",
      "Processed 470000 data in trainset\n",
      "Processed 480000 data in trainset\n",
      "Processed 10000 data in testset\n",
      "Processed 20000 data in testset\n",
      "Processed 30000 data in testset\n",
      "Processed 40000 data in testset\n",
      "Processed 50000 data in testset\n",
      "Processed 60000 data in testset\n",
      "Processed 70000 data in testset\n",
      "Processed 80000 data in testset\n",
      "Processed 90000 data in testset\n",
      "Processed 100000 data in testset\n",
      "Processed 110000 data in testset\n",
      "Processed 120000 data in testset\n",
      "Processed 130000 data in testset\n",
      "Processed 140000 data in testset\n",
      "Processed 150000 data in testset\n",
      "Processed 160000 data in testset\n"
     ]
    }
   ],
   "source": [
    "feature_extractor = FeatureExtractor()\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for i, (state, value) in enumerate(trainset):\n",
    "    X_train.append(feature_extractor.extract_features(state))\n",
    "    y_train.append(value)\n",
    "    if i % 10000 == 9999:\n",
    "        print(f\"Processed {i + 1} data in trainset\")\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "for i, (state, value) in enumerate(testset):\n",
    "    X_test.append(feature_extractor.extract_features(state))\n",
    "    y_test.append(value)\n",
    "    if i % 10000 == 9999:\n",
    "        print(f\"Processed {i + 1} data in testset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: torch.Size([480000, 9, 13])\n",
      "X_test.shape: torch.Size([160000, 9, 13])\n",
      "y_train.shape: torch.Size([480000, 1])\n",
      "y_test.shape: torch.Size([160000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2l/cn9h3p512nnc1jq5n1fzc0000000gn/T/ipykernel_41140/2585004931.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
      "/var/folders/2l/cn9h3p512nnc1jq5n1fzc0000000gn/T/ipykernel_41140/2585004931.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
      "/var/folders/2l/cn9h3p512nnc1jq5n1fzc0000000gn/T/ipykernel_41140/2585004931.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_train = torch.tensor(y_train, dtype=torch.float32).view(-1, 1).to(device)\n",
      "/var/folders/2l/cn9h3p512nnc1jq5n1fzc0000000gn/T/ipykernel_41140/2585004931.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test = torch.tensor(y_test, dtype=torch.float32).view(-1, 1).to(device)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).view(-1, 1).to(device)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32).view(-1, 1).to(device)\n",
    "\n",
    "print(\"X_train.shape:\", X_train.shape)\n",
    "print(\"X_test.shape:\", X_test.shape)\n",
    "print(\"y_train.shape:\", y_train.shape)\n",
    "print(\"y_test.shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Heuristic(nn.Module):\n",
    "    class LocalNN(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Heuristic.LocalNN, self).__init__()\n",
    "            self.fc1 = nn.Linear(13, 32)\n",
    "            self.fc2 = nn.Linear(32, 32)\n",
    "            self.fc3 = nn.Linear(32, 32)\n",
    "            self.fc4 = nn.Linear(32, 1)\n",
    "        \n",
    "        def forward(self, x):\n",
    "            x = F.gelu(self.fc1(x))\n",
    "            x = F.gelu(self.fc2(x))\n",
    "            x = F.gelu(self.fc3(x))\n",
    "            x = F.tanh(self.fc4(x))\n",
    "            return x\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Heuristic, self).__init__()\n",
    "        self.localNN = Heuristic.LocalNN()\n",
    "        self.fc1 = nn.Linear(9, 32)\n",
    "        self.fc2 = nn.Linear(32, 32)\n",
    "        self.fc3 = nn.Linear(32, 32)\n",
    "        self.fc4 = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.localNN(x)\n",
    "        x = F.gelu(self.fc1(x.squeeze(-1)))\n",
    "        x = F.gelu(self.fc2(x))\n",
    "        x = F.gelu(self.fc3(x))\n",
    "        x = F.tanh(self.fc4(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/1000], Loss: 0.3012\n",
      "Epoch [1/10], Step [200/1000], Loss: 0.2442\n",
      "Epoch [1/10], Step [300/1000], Loss: 0.2060\n",
      "Epoch [1/10], Step [400/1000], Loss: 0.1630\n",
      "Epoch [1/10], Step [500/1000], Loss: 0.1435\n",
      "Epoch [1/10], Step [600/1000], Loss: 0.1549\n",
      "Epoch [1/10], Step [700/1000], Loss: 0.1568\n",
      "Epoch [1/10], Step [800/1000], Loss: 0.1441\n",
      "Epoch [1/10], Step [900/1000], Loss: 0.1175\n",
      "Epoch [1/10], Step [1000/1000], Loss: 0.1370\n",
      "Epoch [1/10], Average loss: 0.1997\n",
      "Epoch [2/10], Step [100/1000], Loss: 0.1337\n",
      "Epoch [2/10], Step [200/1000], Loss: 0.1257\n",
      "Epoch [2/10], Step [300/1000], Loss: 0.1512\n",
      "Epoch [2/10], Step [400/1000], Loss: 0.1045\n",
      "Epoch [2/10], Step [500/1000], Loss: 0.1366\n",
      "Epoch [2/10], Step [600/1000], Loss: 0.1238\n",
      "Epoch [2/10], Step [700/1000], Loss: 0.1193\n",
      "Epoch [2/10], Step [800/1000], Loss: 0.1399\n",
      "Epoch [2/10], Step [900/1000], Loss: 0.0969\n",
      "Epoch [2/10], Step [1000/1000], Loss: 0.1174\n",
      "Epoch [2/10], Average loss: 0.1256\n",
      "Epoch [3/10], Step [100/1000], Loss: 0.1257\n",
      "Epoch [3/10], Step [200/1000], Loss: 0.1187\n",
      "Epoch [3/10], Step [300/1000], Loss: 0.1060\n",
      "Epoch [3/10], Step [400/1000], Loss: 0.0976\n",
      "Epoch [3/10], Step [500/1000], Loss: 0.1180\n",
      "Epoch [3/10], Step [600/1000], Loss: 0.0909\n",
      "Epoch [3/10], Step [700/1000], Loss: 0.1157\n",
      "Epoch [3/10], Step [800/1000], Loss: 0.0997\n",
      "Epoch [3/10], Step [900/1000], Loss: 0.1380\n",
      "Epoch [3/10], Step [1000/1000], Loss: 0.1064\n",
      "Epoch [3/10], Average loss: 0.1161\n",
      "Epoch [4/10], Step [100/1000], Loss: 0.1106\n",
      "Epoch [4/10], Step [200/1000], Loss: 0.1110\n",
      "Epoch [4/10], Step [300/1000], Loss: 0.1255\n",
      "Epoch [4/10], Step [400/1000], Loss: 0.1290\n",
      "Epoch [4/10], Step [500/1000], Loss: 0.0873\n",
      "Epoch [4/10], Step [600/1000], Loss: 0.0886\n",
      "Epoch [4/10], Step [700/1000], Loss: 0.1291\n",
      "Epoch [4/10], Step [800/1000], Loss: 0.1102\n",
      "Epoch [4/10], Step [900/1000], Loss: 0.1072\n",
      "Epoch [4/10], Step [1000/1000], Loss: 0.1157\n",
      "Epoch [4/10], Average loss: 0.1118\n",
      "Epoch [5/10], Step [100/1000], Loss: 0.0948\n",
      "Epoch [5/10], Step [200/1000], Loss: 0.1181\n",
      "Epoch [5/10], Step [300/1000], Loss: 0.1071\n",
      "Epoch [5/10], Step [400/1000], Loss: 0.1032\n",
      "Epoch [5/10], Step [500/1000], Loss: 0.0910\n",
      "Epoch [5/10], Step [600/1000], Loss: 0.1234\n",
      "Epoch [5/10], Step [700/1000], Loss: 0.1301\n",
      "Epoch [5/10], Step [800/1000], Loss: 0.1115\n",
      "Epoch [5/10], Step [900/1000], Loss: 0.1162\n",
      "Epoch [5/10], Step [1000/1000], Loss: 0.0781\n",
      "Epoch [5/10], Average loss: 0.1095\n",
      "Epoch [6/10], Step [100/1000], Loss: 0.1158\n",
      "Epoch [6/10], Step [200/1000], Loss: 0.1193\n",
      "Epoch [6/10], Step [300/1000], Loss: 0.0949\n",
      "Epoch [6/10], Step [400/1000], Loss: 0.0811\n",
      "Epoch [6/10], Step [500/1000], Loss: 0.0930\n",
      "Epoch [6/10], Step [600/1000], Loss: 0.1075\n",
      "Epoch [6/10], Step [700/1000], Loss: 0.1164\n",
      "Epoch [6/10], Step [800/1000], Loss: 0.1075\n",
      "Epoch [6/10], Step [900/1000], Loss: 0.1073\n",
      "Epoch [6/10], Step [1000/1000], Loss: 0.1127\n",
      "Epoch [6/10], Average loss: 0.1075\n",
      "Epoch [7/10], Step [100/1000], Loss: 0.1127\n",
      "Epoch [7/10], Step [200/1000], Loss: 0.1031\n",
      "Epoch [7/10], Step [300/1000], Loss: 0.0995\n",
      "Epoch [7/10], Step [400/1000], Loss: 0.1157\n",
      "Epoch [7/10], Step [500/1000], Loss: 0.0822\n",
      "Epoch [7/10], Step [600/1000], Loss: 0.1191\n",
      "Epoch [7/10], Step [700/1000], Loss: 0.0872\n",
      "Epoch [7/10], Step [800/1000], Loss: 0.0883\n",
      "Epoch [7/10], Step [900/1000], Loss: 0.1324\n",
      "Epoch [7/10], Step [1000/1000], Loss: 0.1117\n",
      "Epoch [7/10], Average loss: 0.1060\n",
      "Epoch [8/10], Step [100/1000], Loss: 0.1021\n",
      "Epoch [8/10], Step [200/1000], Loss: 0.1136\n",
      "Epoch [8/10], Step [300/1000], Loss: 0.0731\n",
      "Epoch [8/10], Step [400/1000], Loss: 0.1027\n",
      "Epoch [8/10], Step [500/1000], Loss: 0.1121\n",
      "Epoch [8/10], Step [600/1000], Loss: 0.0981\n",
      "Epoch [8/10], Step [700/1000], Loss: 0.0835\n",
      "Epoch [8/10], Step [800/1000], Loss: 0.1129\n",
      "Epoch [8/10], Step [900/1000], Loss: 0.1080\n",
      "Epoch [8/10], Step [1000/1000], Loss: 0.1518\n",
      "Epoch [8/10], Average loss: 0.1047\n",
      "Epoch [9/10], Step [100/1000], Loss: 0.0834\n",
      "Epoch [9/10], Step [200/1000], Loss: 0.1173\n",
      "Epoch [9/10], Step [300/1000], Loss: 0.0963\n",
      "Epoch [9/10], Step [400/1000], Loss: 0.1097\n",
      "Epoch [9/10], Step [500/1000], Loss: 0.1182\n",
      "Epoch [9/10], Step [600/1000], Loss: 0.1005\n",
      "Epoch [9/10], Step [700/1000], Loss: 0.1047\n",
      "Epoch [9/10], Step [800/1000], Loss: 0.0863\n",
      "Epoch [9/10], Step [900/1000], Loss: 0.1166\n",
      "Epoch [9/10], Step [1000/1000], Loss: 0.0961\n",
      "Epoch [9/10], Average loss: 0.1040\n",
      "Epoch [10/10], Step [100/1000], Loss: 0.0795\n",
      "Epoch [10/10], Step [200/1000], Loss: 0.1049\n",
      "Epoch [10/10], Step [300/1000], Loss: 0.1022\n",
      "Epoch [10/10], Step [400/1000], Loss: 0.1061\n",
      "Epoch [10/10], Step [500/1000], Loss: 0.1149\n",
      "Epoch [10/10], Step [600/1000], Loss: 0.0896\n",
      "Epoch [10/10], Step [700/1000], Loss: 0.1017\n",
      "Epoch [10/10], Step [800/1000], Loss: 0.1122\n",
      "Epoch [10/10], Step [900/1000], Loss: 0.0989\n",
      "Epoch [10/10], Step [1000/1000], Loss: 0.1036\n",
      "Epoch [10/10], Average loss: 0.1025\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "model = Heuristic().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "dataset = TensorDataset(X_train, y_train)\n",
    "dataloader = DataLoader(dataset, batch_size=math.ceil(len(y_train)/1000), shuffle=True)\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0.0\n",
    "    for i, (X_batch, y_batch) in enumerate(dataloader):\n",
    "        X_batch.to(device)\n",
    "        y_batch.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        pred = model(X_batch)\n",
    "        loss = loss_fn(pred, y_batch)\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 100 == 99:\n",
    "            print(f\"Epoch [{epoch + 1}/{epochs}], Step [{i + 1}/{len(dataloader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    average_loss = total_loss / len(dataloader)\n",
    "    print(f\"Epoch [{epoch + 1}/{epochs}], Average loss: {average_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error: 0.10132867097854614\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(precision=10, threshold=torch.inf)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pred = model(X_test)\n",
    "    error = loss_fn(pred, y_test).item()\n",
    "print(\"Test error:\", error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_weights = model.state_dict()\n",
    "with open(\"heuristic.txt\", \"w\") as f:\n",
    "    for key, value in trained_weights.items():\n",
    "        value = value.detach().cpu().numpy().tolist()\n",
    "        f.write(f\"{key.upper()}: {value}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mini-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
